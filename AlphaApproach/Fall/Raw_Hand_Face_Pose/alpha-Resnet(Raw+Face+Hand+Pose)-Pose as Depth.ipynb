{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0i9JxAw5Z3-n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "from PIL import Image  , ImageDraw \n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2075,
     "status": "ok",
     "timestamp": 1576133810310,
     "user": {
      "displayName": "i160249 Govinda Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCG7LO_4Lf9KneuAwHecGzTxO970RJ3m0-iLHf3=s64",
      "userId": "01125797756988197357"
     },
     "user_tz": -300
    },
    "id": "dLlPuZDva4LQ",
    "outputId": "87743a2f-c94e-4405-e63f-4759f95d3f50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24764,
     "status": "ok",
     "timestamp": 1580209595805,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "HIVarKtQbBSW",
    "outputId": "ad6c96ca-bcb5-411e-9b03-462d3edd3946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5891,
     "status": "ok",
     "timestamp": 1576133836509,
     "user": {
      "displayName": "i160249 Govinda Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCG7LO_4Lf9KneuAwHecGzTxO970RJ3m0-iLHf3=s64",
      "userId": "01125797756988197357"
     },
     "user_tz": -300
    },
    "id": "vuG2YVq0cMKc",
    "outputId": "c0b7d91a-8f9d-4df3-bacf-2cd48010a41c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "%cd drive/My Drive/Resnet_Beta-Version\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6vN1vJhBo7v"
   },
   "outputs": [],
   "source": [
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1580210225848,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "CIS1JQp_cxi4",
    "outputId": "1597b926-7b18-4722-b8f1-41d0a07f3418"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTest Code\\n\\n\\npath, target = self.samples[index]\\nsample = self.loader(path)\\nif self.transform is not None:\\n  sample = self.transform(sample)\\nif self.target_transform is not None:\\n  target = self.target_transform(target)\\n# this is where you load your resnet data\\nresnet_path = os.path.join(os.path.splitext(path)[0], \\'.pth\\')  # replace image extension with .pth\\nresnet = torch.load(resnet_path)  # load the stored features\\nreturn sample, resnet, target\\n\\n#dataset = MyImageFolder(\"falling_dataset/val/\")\\n#dataset[0]\\n#h = dataset.get_heatmap_pose(\"falling_dataset/train/Falling/11107.json\",1280,720)\\n#print(len(h))\\n#for i in range(len(h)):\\n#    h[i].save(\"Annotated/train/%d.jpg\"%(i))\\n\\npath = \"./falling_dataset/train/Falling\"\\n!pwd\\nfor file in os.listdir(path):\\n    if file.endswith(\".json\"):\\n        #print(os.path.join(path, file))\\n\\n        with open(os.path.join(path, file)) as f:\\n            string = f.readline()\\n            if string == \\'[]\\':\\n                print(os.path.join(path, file))\\n\\n\\n\\n#re, labels = dataset[1:3]\\n#print(re)\\n#print(labels)\\n#re[2].save(\\'pred_face.jpeg\\')\\n#re[3].save(\\'pred_hand.jpeg\\')\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class MyImageFolder(datasets.ImageFolder):\n",
    "    \n",
    "    def __init__(self, root, transform=None):\n",
    "        super(MyImageFolder,self).__init__(root)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #imgs = self.imgs[index]\n",
    "        #print(imgs)\n",
    "\n",
    "        path, target = self.samples[index]\n",
    "        #sample = self.loader(path)\n",
    "        #print(\"Sample: \",sample)\n",
    "        \n",
    "\n",
    "        hm_transform = transforms.Compose([\n",
    "                          transforms.Resize((224,224)),\n",
    "                          transforms.ToTensor()\n",
    "\n",
    "                                ])\n",
    "        self.transform = hm_transform\n",
    "        #print(path)\n",
    "        #print(type(path))\n",
    "        #all_images = []\n",
    "        #all_labels = []\n",
    "        #all_hm_face = []\n",
    "        #all_hm_hand = []\n",
    "        # target_acquired - 0: image path -- 1: label\n",
    "        #for i in len(path):\n",
    "\n",
    "        img_path = path\n",
    "        #print(\"--i: %d , TA: %s\"%(i,target_acquired))\n",
    "\n",
    "        \n",
    "        #img_path = target_acquired\n",
    "        #label =  target_acquired[1]\n",
    "\n",
    "        #print(img_path)\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        img_w , img_h = image.size\n",
    "\n",
    "    \n",
    "        filename = os.path.basename(img_path)\n",
    "        ann_path = img_path.replace(filename, filename.split('.')[0])\n",
    "        hm_face , hm_hand = self.get_heatmap(ann_path + '.txt',img_w,img_h)  \n",
    "        hm_pose = self.get_heatmap_pose(ann_path + '.json',img_w,img_h)\n",
    "        #image = np.dstack((image, hm_face))\n",
    "\n",
    "        \n",
    "        # Transforms\n",
    "        if self.transform is not None:\n",
    "            \n",
    "            image = self.transform(image)\n",
    "            hm_face = hm_transform(hm_face)\n",
    "            hm_hand = hm_transform(hm_hand)\n",
    "            hm_pose = torch.stack([ hm_transform(x) for x in hm_pose ], dim=1).squeeze(0)\n",
    "\n",
    "\n",
    "        #print( hm_pose.size() )\n",
    "        image = torch.cat((image,hm_face,hm_hand,hm_pose))\n",
    "       \n",
    "        #print(image.size())\n",
    "        #if self.target_transform is not None:\n",
    "        #    target = self.target_transform(target)\n",
    "        \n",
    "        \n",
    "        # For Face\n",
    "            #image = np.dstack((image, hm_face))\n",
    "\n",
    "            #all_images.append(img_path)\n",
    "            #all_labels.append(label)\n",
    "            #all_hm_face.append(hm_face)\n",
    "            #all_hm_hand.append(hm_hand)\n",
    "\n",
    "        #return path, all_hm_face, all_hm_hand, target\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def get_heatmap(self,ann_path, img_w , img_h):\n",
    "        \n",
    "        hm_0 = Image.new('L', (img_w, img_h))\n",
    "        hm_1 = Image.new('L', (img_w, img_h))\n",
    "        \n",
    "        try:\n",
    "\n",
    "            with open(ann_path) as f:\n",
    "\n",
    "                for line in f.readlines():\n",
    "\n",
    "                    if line == '\\n':\n",
    "                        continue\n",
    "\n",
    "                    line = line.split(' ')\n",
    "\n",
    "                    cx = float(line[1])\n",
    "                    cy = float(line[2])\n",
    "                    w = float(line[3])\n",
    "                    h = float(line[4])\n",
    "\n",
    "                    xmin =  (cx - (w/2)) * img_w\n",
    "                    ymin = (cy - (h/2)) * img_h\n",
    "                    xmax = (cx + (w/2)) * img_w\n",
    "                    ymax = (cy + (h/2)) * img_h\n",
    "\n",
    "                    if line[0] == '0':\n",
    "                        hmDraw = ImageDraw.Draw(hm_0)   \n",
    "                    else:\n",
    "                        hmDraw = ImageDraw.Draw(hm_1)   \n",
    "                    \n",
    "                    hmDraw.rectangle([xmin,ymin,xmax,ymax], fill =\"#ffffff\")\n",
    "        except FileNotFoundError:\n",
    "            #print(\"FileNotFoundError: %s\"%ann_path)\n",
    "            pass\n",
    "\n",
    "        return hm_0, hm_1\n",
    "\n",
    "    def get_heatmap_pose(self,ann_path, img_w, img_h):\n",
    "        \n",
    "        heatmaps = [ Image.new('L', (img_w, img_h)) for x in range(17) ]\n",
    "\n",
    "        try:\n",
    "            with open(ann_path,'r') as f:\n",
    "                data = json.load(f)\n",
    "            #print(ann_path)\n",
    "            #print(data)  \n",
    "            try:\n",
    "                keypoints = data[0]['keypoints']\n",
    "            except IndexError:\n",
    "                return heatmaps\n",
    "\n",
    "            #print(keypoints)\n",
    "            # TODO check for two key mappings -- working\n",
    "\n",
    "            for i in range(0,len(keypoints),3):\n",
    "\n",
    "                xmin = keypoints[i] - 5\n",
    "                ymin = keypoints[i+1] - 5\n",
    "                xmax = keypoints[i] + 5\n",
    "                ymax = keypoints[i+1] + 5\n",
    "\n",
    "                hmDraw = ImageDraw.Draw(heatmaps[i//3]) \n",
    "                hmDraw.rectangle([xmin,ymin,xmax,ymax], fill =\"#ffffff\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            #print(\"FileNotFoundError: %s\"%ann_path)\n",
    "            pass\n",
    "\n",
    "        return heatmaps\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Test Code\n",
    "\n",
    "\n",
    "path, target = self.samples[index]\n",
    "sample = self.loader(path)\n",
    "if self.transform is not None:\n",
    "  sample = self.transform(sample)\n",
    "if self.target_transform is not None:\n",
    "  target = self.target_transform(target)\n",
    "# this is where you load your resnet data\n",
    "resnet_path = os.path.join(os.path.splitext(path)[0], '.pth')  # replace image extension with .pth\n",
    "resnet = torch.load(resnet_path)  # load the stored features\n",
    "return sample, resnet, target\n",
    "\n",
    "#dataset = MyImageFolder(\"falling_dataset/val/\")\n",
    "#dataset[0]\n",
    "#h = dataset.get_heatmap_pose(\"falling_dataset/train/Falling/11107.json\",1280,720)\n",
    "#print(len(h))\n",
    "#for i in range(len(h)):\n",
    "#    h[i].save(\"Annotated/train/%d.jpg\"%(i))\n",
    "\n",
    "path = \"./falling_dataset/train/Falling\"\n",
    "!pwd\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".json\"):\n",
    "        #print(os.path.join(path, file))\n",
    "\n",
    "        with open(os.path.join(path, file)) as f:\n",
    "            string = f.readline()\n",
    "            if string == '[]':\n",
    "                print(os.path.join(path, file))\n",
    "\n",
    "\n",
    "\n",
    "#re, labels = dataset[1:3]\n",
    "#print(re)\n",
    "#print(labels)\n",
    "#re[2].save('pred_face.jpeg')\n",
    "#re[3].save('pred_hand.jpeg')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvPZnmxkck5v"
   },
   "outputs": [],
   "source": [
    "input_path = './alpha-dataset'\n",
    "\n",
    "image_datasets = {\n",
    "    'train': \n",
    "    MyImageFolder(input_path + '/train_m', data_transforms['train']),\n",
    "    'validation': \n",
    "    MyImageFolder(input_path + '/val_m', data_transforms['validation'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train':\n",
    "    torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                batch_size=64,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0),  # for Kaggle\n",
    "    'validation':\n",
    "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                batch_size=32,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0)  # for Kaggle\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1580210235403,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "xafZq403ctQr",
    "outputId": "514ae5af-671a-451e-ff17-e5eb8a47cf63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13528,
     "status": "ok",
     "timestamp": 1580116812973,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "9YGQVaU6dZ_x",
    "outputId": "5d9fe97a-f463-4715-a1a8-a1d3e4ee38c8"
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "model.cuda()\n",
    "#print(model)\n",
    "\n",
    "depth = 22    # ( 3 + 1 + 1 + 17 )\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "\n",
    "\n",
    "#------------ Modify First Layer\n",
    "model.conv1 = nn.Conv2d(depth, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False).to(device)\n",
    "model.conv1.requires_grad = True\n",
    "\n",
    "#------------ Modify Last Layer\n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 2),\n",
    "               nn.Sigmoid()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKERKEVbdhW6"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92MccuHRdktd"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        f = open('loss/alpha/raw-face-hand-pose.txt','a+')\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        f.write('Epoch {}/{}\\n'.format(epoch+1, num_epochs))\n",
    "        \n",
    "\n",
    "        for phase in ['train','validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            count = 0\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "              for inputs, labels in dataloaders[phase]:\n",
    "                  inputs = inputs.to(device)\n",
    "                  labels = labels.to(device)\n",
    "\n",
    "                  outputs = model(inputs)\n",
    "                  loss = criterion(outputs, labels)\n",
    "\n",
    "                  if phase == 'train':\n",
    "                      \n",
    "                      optimizer.zero_grad()\n",
    "                      loss.backward()\n",
    "                      optimizer.step()\n",
    "\n",
    "                  _, preds = torch.max(outputs, 1)\n",
    "                  running_loss += loss.item() * inputs.size(0)\n",
    "                  running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                  count = count+1                \n",
    "                  if (count%40==0):\n",
    "                    print (count)\n",
    "             \n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,epoch_loss,epoch_acc))\n",
    "            f.write('{} loss: {:.4f}, acc: {:.4f}\\n'.format(phase,epoch_loss,epoch_acc))\n",
    "              \n",
    "            \n",
    "        torch.save(model, 'weights/alpha/raw-face-hand-pose/epoch_%d.pth'%(epoch))\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10886084,
     "status": "ok",
     "timestamp": 1580170498786,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "D1QckUERdrFV",
    "outputId": "4065062d-5b81-41f5-8698-0cfa35a27d38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.5718, acc: 0.7435\n",
      "validation loss: 0.5776, acc: 0.7193\n",
      "Epoch 2/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.5294, acc: 0.7832\n",
      "validation loss: 0.5266, acc: 0.7789\n",
      "Epoch 3/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.5112, acc: 0.8012\n",
      "validation loss: 0.5239, acc: 0.7897\n",
      "Epoch 4/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4953, acc: 0.8192\n",
      "validation loss: 0.4985, acc: 0.8014\n",
      "Epoch 5/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4829, acc: 0.8329\n",
      "validation loss: 0.5331, acc: 0.7681\n",
      "Epoch 6/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4832, acc: 0.8254\n",
      "validation loss: 0.5245, acc: 0.7807\n",
      "Epoch 7/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4832, acc: 0.8231\n",
      "validation loss: 0.4822, acc: 0.8204\n",
      "Epoch 8/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4693, acc: 0.8442\n",
      "validation loss: 0.4894, acc: 0.8168\n",
      "Epoch 9/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4616, acc: 0.8504\n",
      "validation loss: 0.4726, acc: 0.8339\n",
      "Epoch 10/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4646, acc: 0.8481\n",
      "validation loss: 0.4703, acc: 0.8384\n",
      "Epoch 11/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4594, acc: 0.8537\n",
      "validation loss: 0.5238, acc: 0.7744\n",
      "Epoch 12/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4623, acc: 0.8481\n",
      "validation loss: 0.4799, acc: 0.8339\n",
      "Epoch 13/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4533, acc: 0.8548\n",
      "validation loss: 0.4717, acc: 0.8421\n",
      "Epoch 14/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4537, acc: 0.8568\n",
      "validation loss: 0.4610, acc: 0.8439\n",
      "Epoch 15/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4498, acc: 0.8602\n",
      "validation loss: 0.4678, acc: 0.8375\n",
      "Epoch 16/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4492, acc: 0.8612\n",
      "validation loss: 0.4680, acc: 0.8394\n",
      "Epoch 17/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4463, acc: 0.8643\n",
      "validation loss: 0.4899, acc: 0.8213\n",
      "Epoch 18/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4376, acc: 0.8754\n",
      "validation loss: 0.4547, acc: 0.8421\n",
      "Epoch 19/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4374, acc: 0.8738\n",
      "validation loss: 0.4534, acc: 0.8556\n",
      "Epoch 20/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4348, acc: 0.8717\n",
      "validation loss: 0.4703, acc: 0.8366\n",
      "Epoch 21/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4407, acc: 0.8717\n",
      "validation loss: 0.4494, acc: 0.8574\n",
      "Epoch 22/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4248, acc: 0.8869\n",
      "validation loss: 0.4532, acc: 0.8601\n",
      "Epoch 23/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4274, acc: 0.8867\n",
      "validation loss: 0.4666, acc: 0.8421\n",
      "Epoch 24/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4363, acc: 0.8748\n",
      "validation loss: 0.4467, acc: 0.8565\n",
      "Epoch 25/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4227, acc: 0.8908\n",
      "validation loss: 0.4556, acc: 0.8502\n",
      "Epoch 26/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4299, acc: 0.8756\n",
      "validation loss: 0.4431, acc: 0.8637\n",
      "Epoch 27/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4313, acc: 0.8790\n",
      "validation loss: 0.4484, acc: 0.8628\n",
      "Epoch 28/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4248, acc: 0.8869\n",
      "validation loss: 0.4429, acc: 0.8691\n",
      "Epoch 29/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4323, acc: 0.8759\n",
      "validation loss: 0.4737, acc: 0.8312\n",
      "Epoch 30/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4240, acc: 0.8862\n",
      "validation loss: 0.4424, acc: 0.8691\n",
      "Epoch 31/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4190, acc: 0.8924\n",
      "validation loss: 0.4474, acc: 0.8592\n",
      "Epoch 32/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4153, acc: 0.9003\n",
      "validation loss: 0.4578, acc: 0.8475\n",
      "Epoch 33/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4234, acc: 0.8885\n",
      "validation loss: 0.4535, acc: 0.8529\n",
      "Epoch 34/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4314, acc: 0.8777\n",
      "validation loss: 0.4397, acc: 0.8709\n",
      "Epoch 35/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4172, acc: 0.8962\n",
      "validation loss: 0.4387, acc: 0.8709\n",
      "Epoch 36/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4142, acc: 0.9003\n",
      "validation loss: 0.4379, acc: 0.8691\n",
      "Epoch 37/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4109, acc: 0.9042\n",
      "validation loss: 0.4395, acc: 0.8691\n",
      "Epoch 38/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4220, acc: 0.8887\n",
      "validation loss: 0.4372, acc: 0.8736\n",
      "Epoch 39/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4076, acc: 0.9063\n",
      "validation loss: 0.4374, acc: 0.8673\n",
      "Epoch 40/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4142, acc: 0.8952\n",
      "validation loss: 0.4541, acc: 0.8538\n",
      "Epoch 41/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4176, acc: 0.8931\n",
      "validation loss: 0.4466, acc: 0.8655\n",
      "Epoch 42/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4251, acc: 0.8823\n",
      "validation loss: 0.4650, acc: 0.8466\n",
      "Epoch 43/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4136, acc: 0.8960\n",
      "validation loss: 0.4377, acc: 0.8709\n",
      "Epoch 44/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4082, acc: 0.9037\n",
      "validation loss: 0.4562, acc: 0.8448\n",
      "Epoch 45/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4069, acc: 0.9052\n",
      "validation loss: 0.4346, acc: 0.8764\n",
      "Epoch 46/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4031, acc: 0.9075\n",
      "validation loss: 0.4329, acc: 0.8709\n",
      "Epoch 47/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3980, acc: 0.9142\n",
      "validation loss: 0.4343, acc: 0.8745\n",
      "Epoch 48/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4068, acc: 0.9050\n",
      "validation loss: 0.4432, acc: 0.8628\n",
      "Epoch 49/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4155, acc: 0.8939\n",
      "validation loss: 0.4348, acc: 0.8727\n",
      "Epoch 50/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3997, acc: 0.9137\n",
      "validation loss: 0.4362, acc: 0.8691\n",
      "Epoch 51/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3998, acc: 0.9122\n",
      "validation loss: 0.4518, acc: 0.8538\n",
      "Epoch 52/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4059, acc: 0.9052\n",
      "validation loss: 0.4391, acc: 0.8664\n",
      "Epoch 53/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4126, acc: 0.8965\n",
      "validation loss: 0.4303, acc: 0.8773\n",
      "Epoch 54/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4008, acc: 0.9117\n",
      "validation loss: 0.4293, acc: 0.8809\n",
      "Epoch 55/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4155, acc: 0.8926\n",
      "validation loss: 0.4428, acc: 0.8637\n",
      "Epoch 56/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4014, acc: 0.9086\n",
      "validation loss: 0.4510, acc: 0.8574\n",
      "Epoch 57/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4182, acc: 0.8898\n",
      "validation loss: 0.4304, acc: 0.8791\n",
      "Epoch 58/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3929, acc: 0.9209\n",
      "validation loss: 0.4284, acc: 0.8836\n",
      "Epoch 59/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4252, acc: 0.8810\n",
      "validation loss: 0.4474, acc: 0.8592\n",
      "Epoch 60/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3983, acc: 0.9122\n",
      "validation loss: 0.4340, acc: 0.8745\n",
      "Epoch 61/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3980, acc: 0.9150\n",
      "validation loss: 0.4383, acc: 0.8709\n",
      "Epoch 62/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4307, acc: 0.8777\n",
      "validation loss: 0.4290, acc: 0.8800\n",
      "Epoch 63/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4028, acc: 0.9081\n",
      "validation loss: 0.4288, acc: 0.8809\n",
      "Epoch 64/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3927, acc: 0.9189\n",
      "validation loss: 0.4285, acc: 0.8809\n",
      "Epoch 65/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3953, acc: 0.9158\n",
      "validation loss: 0.4291, acc: 0.8827\n",
      "Epoch 66/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3937, acc: 0.9191\n",
      "validation loss: 0.4352, acc: 0.8700\n",
      "Epoch 67/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4010, acc: 0.9075\n",
      "validation loss: 0.4625, acc: 0.8520\n",
      "Epoch 68/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3974, acc: 0.9148\n",
      "validation loss: 0.4260, acc: 0.8818\n",
      "Epoch 69/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3968, acc: 0.9117\n",
      "validation loss: 0.4333, acc: 0.8700\n",
      "Epoch 70/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3954, acc: 0.9142\n",
      "validation loss: 0.4249, acc: 0.8845\n",
      "Epoch 71/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4096, acc: 0.8998\n",
      "validation loss: 0.4238, acc: 0.8890\n",
      "Epoch 72/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3996, acc: 0.9114\n",
      "validation loss: 0.4258, acc: 0.8827\n",
      "Epoch 73/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3966, acc: 0.9171\n",
      "validation loss: 0.4227, acc: 0.8881\n",
      "Epoch 74/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3993, acc: 0.9091\n",
      "validation loss: 0.4262, acc: 0.8836\n",
      "Epoch 75/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3900, acc: 0.9220\n",
      "validation loss: 0.4301, acc: 0.8736\n",
      "Epoch 76/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3890, acc: 0.9225\n",
      "validation loss: 0.4421, acc: 0.8673\n",
      "Epoch 77/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3900, acc: 0.9199\n",
      "validation loss: 0.4277, acc: 0.8791\n",
      "Epoch 78/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3883, acc: 0.9238\n",
      "validation loss: 0.4367, acc: 0.8682\n",
      "Epoch 79/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3969, acc: 0.9122\n",
      "validation loss: 0.4270, acc: 0.8827\n",
      "Epoch 80/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3856, acc: 0.9258\n",
      "validation loss: 0.4250, acc: 0.8845\n",
      "Epoch 81/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3947, acc: 0.9160\n",
      "validation loss: 0.4259, acc: 0.8800\n",
      "Epoch 82/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3893, acc: 0.9227\n",
      "validation loss: 0.4225, acc: 0.8827\n",
      "Epoch 83/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3821, acc: 0.9302\n",
      "validation loss: 0.4274, acc: 0.8818\n",
      "Epoch 84/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3843, acc: 0.9294\n",
      "validation loss: 0.4292, acc: 0.8791\n",
      "Epoch 85/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3936, acc: 0.9176\n",
      "validation loss: 0.4191, acc: 0.8890\n",
      "Epoch 86/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3880, acc: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 0.4213, acc: 0.8890\n",
      "Epoch 87/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3894, acc: 0.9240\n",
      "validation loss: 0.4247, acc: 0.8854\n",
      "Epoch 88/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3823, acc: 0.9292\n",
      "validation loss: 0.4253, acc: 0.8818\n",
      "Epoch 89/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3846, acc: 0.9269\n",
      "validation loss: 0.4605, acc: 0.8412\n",
      "Epoch 90/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.4120, acc: 0.8957\n",
      "validation loss: 0.4183, acc: 0.8917\n",
      "Epoch 91/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3869, acc: 0.9256\n",
      "validation loss: 0.4682, acc: 0.8366\n",
      "Epoch 92/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3928, acc: 0.9186\n",
      "validation loss: 0.4209, acc: 0.8908\n",
      "Epoch 93/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3816, acc: 0.9315\n",
      "validation loss: 0.4188, acc: 0.8908\n",
      "Epoch 94/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3877, acc: 0.9240\n",
      "validation loss: 0.4434, acc: 0.8637\n",
      "Epoch 95/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3882, acc: 0.9238\n",
      "validation loss: 0.4197, acc: 0.8908\n",
      "Epoch 96/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3797, acc: 0.9310\n",
      "validation loss: 0.4197, acc: 0.8917\n",
      "Epoch 97/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3740, acc: 0.9400\n",
      "validation loss: 0.4179, acc: 0.8935\n",
      "Epoch 98/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3805, acc: 0.9336\n",
      "validation loss: 0.4216, acc: 0.8899\n",
      "Epoch 99/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3753, acc: 0.9366\n",
      "validation loss: 0.4243, acc: 0.8854\n",
      "Epoch 100/100\n",
      "----------\n",
      "40\n",
      "train loss: 0.3771, acc: 0.9374\n",
      "validation loss: 0.4221, acc: 0.8854\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwFiKhYJtD0k"
   },
   "outputs": [],
   "source": [
    "torch.save(model_ trained.state_dict(), 'weights/pytorch/weightsE3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3L_ZM8xFtNs8"
   },
   "outputs": [],
   "source": [
    "# model = models.resnet50(pretrained=False).to(device)\n",
    "# model.fc = nn.Sequential(\n",
    "#                nn.Linear(2048, 128),\n",
    "#                nn.ReLU(inplace=True),\n",
    "#                nn.Linear(128, 2)).to(device)\n",
    "epoch = 99\n",
    "model = (torch.load('weights/raw-face-hand-pose-d/rfhp_epoch_%d.pth'%epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5582,
     "status": "ok",
     "timestamp": 1575392566608,
     "user": {
      "displayName": "Muhammad Arslan",
      "photoUrl": "",
      "userId": "03998929032390632573"
     },
     "user_tz": -300
    },
    "id": "6Y8rCEFjtrpC",
    "outputId": "2ce69ff2-9426-451f-ea46-ac94959b74ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darknet\t\t      examples\t      opt.py\t\ttrain_sppe\n",
      "data\t\t      fallmodel.pth   output\t\tvideo_ann.py\n",
      "datalabeler_101.py    fi_data\t      PoseFlow\t\tvideo_demo.py\n",
      "datalabeler_111.py    fn.py\t      pPose_nms.py\twebcam_demo.py\n",
      "datalabeler_249.py    img.png\t      __pycache__\tweights\n",
      "dataloader.py\t      LICENSE\t      README.md\t\tyolo\n",
      "dataloader_webcam.py  matching.py     requirements.txt\n",
      "demo.py\t\t      models\t      resnetWeights\n",
      "doc\t\t      online_demo.py  SPPE\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62654,
     "status": "ok",
     "timestamp": 1580209956564,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "wq4G8lVstYvb",
    "outputId": "f8348943-02e7-438d-ae9d-e884ce2dd955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "pathFalling = '/content/drive/My Drive/AlphaPose/AlphaPose-pytorch/fi_data/train/Falling/'\n",
    "pathNonFalling = '/content/drive/My Drive/AlphaPose/AlphaPose-pytorch/fi_data/train/NonFalling/'\n",
    "accurateFalling = 0\n",
    "accurateNonFalling = 0\n",
    "\n",
    "list1= [f for f in glob.glob(pathFalling + \"*.jpg\", recursive=True)]\n",
    "list2= [f for f in glob.glob(pathNonFalling + \"*.jpg\", recursive=True)]\n",
    "validation_img_pathsFalling=random.sample(list1,100)\n",
    "validation_img_pathsNonFalling = random.sample(list2,100)\n",
    "img_listFalling = [Image.open('' + img_path) for img_path in validation_img_pathsFalling]\n",
    "img_listNonFalling = [Image.open('' + img_path) for img_path in validation_img_pathsNonFalling]\n",
    "print (len(img_listFalling))\n",
    "print (len(img_listNonFalling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYOIdD9guYph"
   },
   "outputs": [],
   "source": [
    "validation_batchFalling = torch.stack([data_transforms['validation'](img).to(device)\n",
    "                                for img in img_listFalling])\n",
    "validation_batchNonFalling = torch.stack([data_transforms['validation'](img).to(device)\n",
    "                                for img in img_listNonFalling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 882,
     "status": "error",
     "timestamp": 1580210014453,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "NRZ-A7K4ugem",
    "outputId": "a049c533-6100-4389-8a36-cfacb50828e1"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2113ed60ac6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_logits_tensorFalling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_batchFalling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_logits_tensorFalling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_logits_tensorNonFalling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_batchNonFalling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_logits_tensorNonFalling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 64 22 7 7, expected input[100, 3, 224, 224] to have 22 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "pred_logits_tensorFalling = model(validation_batchFalling)\n",
    "pred_logits_tensorFalling\n",
    "pred_logits_tensorNonFalling = model(validation_batchNonFalling)\n",
    "pred_logits_tensorNonFalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1247,
     "status": "ok",
     "timestamp": 1575488574340,
     "user": {
      "displayName": "Muhammad Arslan",
      "photoUrl": "",
      "userId": "03998929032390632573"
     },
     "user_tz": -300
    },
    "id": "q85S6UXtukcS",
    "outputId": "d0955b06-a0bc-41b5-d9fa-075ebcb97f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44844374 0.5515562 ]\n",
      " [0.12725133 0.8727487 ]\n",
      " [0.09804448 0.9019555 ]\n",
      " [0.00425655 0.99574345]\n",
      " [0.8194356  0.18056442]\n",
      " [0.24643923 0.7535607 ]\n",
      " [0.13835269 0.8616473 ]\n",
      " [0.1574074  0.84259254]\n",
      " [0.8485861  0.1514139 ]\n",
      " [0.32346088 0.6765391 ]\n",
      " [0.41357878 0.58642125]\n",
      " [0.15117285 0.8488271 ]\n",
      " [0.6003375  0.39966255]\n",
      " [0.02290936 0.9770906 ]\n",
      " [0.10023551 0.89976454]\n",
      " [0.29872367 0.70127636]\n",
      " [0.04371396 0.956286  ]\n",
      " [0.61934406 0.38065597]\n",
      " [0.30597326 0.6940267 ]\n",
      " [0.16753031 0.8324697 ]\n",
      " [0.66433    0.33567002]\n",
      " [0.84191    0.15808995]\n",
      " [0.6628018  0.33719823]\n",
      " [0.4977156  0.50228435]\n",
      " [0.87176895 0.12823105]\n",
      " [0.02149463 0.9785054 ]\n",
      " [0.48655316 0.5134468 ]\n",
      " [0.44041517 0.55958486]\n",
      " [0.1114507  0.88854927]\n",
      " [0.5616096  0.4383904 ]\n",
      " [0.570884   0.42911607]\n",
      " [0.32838956 0.6716105 ]\n",
      " [0.42478982 0.5752102 ]\n",
      " [0.5371839  0.46281612]\n",
      " [0.02694354 0.9730565 ]\n",
      " [0.61242115 0.3875789 ]\n",
      " [0.21000993 0.7899901 ]\n",
      " [0.32981074 0.6701893 ]\n",
      " [0.23768397 0.76231605]\n",
      " [0.846486   0.15351407]\n",
      " [0.68354267 0.3164573 ]\n",
      " [0.4176136  0.58238643]\n",
      " [0.06766645 0.9323336 ]\n",
      " [0.69376177 0.30623817]\n",
      " [0.9771763  0.02282374]\n",
      " [0.07331121 0.92668885]\n",
      " [0.11293977 0.8870603 ]\n",
      " [0.37429568 0.6257043 ]\n",
      " [0.7112252  0.2887748 ]\n",
      " [0.5165122  0.4834878 ]\n",
      " [0.47287163 0.52712834]\n",
      " [0.96339136 0.03660858]\n",
      " [0.7991366  0.2008634 ]\n",
      " [0.49161175 0.5083883 ]\n",
      " [0.8278209  0.17217906]\n",
      " [0.24142899 0.75857097]\n",
      " [0.5952337  0.40476635]\n",
      " [0.49367377 0.50632626]\n",
      " [0.7527855  0.24721453]\n",
      " [0.6790213  0.3209787 ]\n",
      " [0.21791002 0.78209   ]\n",
      " [0.06385373 0.93614626]\n",
      " [0.90989935 0.09010066]\n",
      " [0.02374623 0.9762538 ]\n",
      " [0.8750763  0.12492373]\n",
      " [0.62880886 0.3711911 ]\n",
      " [0.19562398 0.80437607]\n",
      " [0.53961694 0.46038303]\n",
      " [0.96837336 0.03162658]\n",
      " [0.8945824  0.10541761]\n",
      " [0.19153614 0.8084639 ]\n",
      " [0.14318709 0.8568129 ]\n",
      " [0.44895428 0.5510457 ]\n",
      " [0.8236538  0.17634615]\n",
      " [0.08415014 0.91584986]\n",
      " [0.47937563 0.52062434]\n",
      " [0.19345781 0.80654216]\n",
      " [0.9406548  0.05934522]\n",
      " [0.36073017 0.6392699 ]\n",
      " [0.30378166 0.6962183 ]\n",
      " [0.47753116 0.5224688 ]\n",
      " [0.8833815  0.1166185 ]\n",
      " [0.9168655  0.08313444]\n",
      " [0.87966335 0.12033666]\n",
      " [0.42452285 0.5754772 ]\n",
      " [0.5606509  0.43934906]\n",
      " [0.95545757 0.04454246]\n",
      " [0.02084625 0.97915375]\n",
      " [0.67413664 0.32586333]\n",
      " [0.17854933 0.82145065]\n",
      " [0.7842554  0.21574464]\n",
      " [0.26769415 0.7323058 ]\n",
      " [0.26496124 0.73503876]\n",
      " [0.06646793 0.93353206]\n",
      " [0.8822006  0.11779939]\n",
      " [0.05985904 0.94014096]\n",
      " [0.04355145 0.9564486 ]\n",
      " [0.8923812  0.10761879]\n",
      " [0.09279072 0.90720934]\n",
      " [0.42540407 0.57459587]]\n",
      "[[8.05502161e-02 9.19449747e-01]\n",
      " [1.28486678e-02 9.87151384e-01]\n",
      " [2.41728546e-03 9.97582674e-01]\n",
      " [1.11064157e-02 9.88893569e-01]\n",
      " [1.05341099e-01 8.94658864e-01]\n",
      " [2.05770060e-01 7.94229925e-01]\n",
      " [1.43593565e-01 8.56406450e-01]\n",
      " [3.10731353e-04 9.99689341e-01]\n",
      " [3.11614215e-01 6.88385785e-01]\n",
      " [2.13098362e-01 7.86901593e-01]\n",
      " [1.15691423e-02 9.88430858e-01]\n",
      " [4.88659777e-02 9.51133966e-01]\n",
      " [2.16933161e-01 7.83066809e-01]\n",
      " [7.13363709e-03 9.92866397e-01]\n",
      " [4.78038967e-01 5.21961033e-01]\n",
      " [5.95515013e-01 4.04484987e-01]\n",
      " [3.80652174e-02 9.61934805e-01]\n",
      " [1.00526935e-03 9.98994768e-01]\n",
      " [2.90798303e-03 9.97092009e-01]\n",
      " [2.68526822e-01 7.31473207e-01]\n",
      " [4.00857069e-02 9.59914267e-01]\n",
      " [5.57824038e-03 9.94421780e-01]\n",
      " [4.36837319e-04 9.99563158e-01]\n",
      " [1.01374899e-05 9.99989867e-01]\n",
      " [1.78716421e-01 8.21283519e-01]\n",
      " [8.52426410e-01 1.47573620e-01]\n",
      " [7.46767297e-02 9.25323308e-01]\n",
      " [1.18349954e-01 8.81650031e-01]\n",
      " [2.32960971e-04 9.99767005e-01]\n",
      " [1.17967539e-01 8.82032514e-01]\n",
      " [8.90307575e-02 9.10969198e-01]\n",
      " [6.37839213e-02 9.36216056e-01]\n",
      " [3.98703031e-02 9.60129678e-01]\n",
      " [1.70634054e-02 9.82936621e-01]\n",
      " [3.47474031e-02 9.65252638e-01]\n",
      " [4.51333597e-02 9.54866588e-01]\n",
      " [6.29067048e-02 9.37093318e-01]\n",
      " [2.42656589e-01 7.57343411e-01]\n",
      " [8.89915787e-03 9.91100848e-01]\n",
      " [3.96270677e-03 9.96037304e-01]\n",
      " [8.89314786e-02 9.11068559e-01]\n",
      " [2.38434616e-02 9.76156533e-01]\n",
      " [4.29177198e-05 9.99957085e-01]\n",
      " [4.11140820e-04 9.99588907e-01]\n",
      " [3.03891860e-03 9.96961057e-01]\n",
      " [3.91045928e-01 6.08954072e-01]\n",
      " [1.08910650e-01 8.91089320e-01]\n",
      " [1.14294803e-02 9.88570511e-01]\n",
      " [1.44592719e-04 9.99855399e-01]\n",
      " [6.85031340e-02 9.31496859e-01]\n",
      " [1.83892608e-01 8.16107392e-01]\n",
      " [1.83594838e-01 8.16405177e-01]\n",
      " [3.26053500e-01 6.73946500e-01]\n",
      " [2.21319690e-01 7.78680325e-01]\n",
      " [2.19887495e-01 7.80112505e-01]\n",
      " [5.88144884e-02 9.41185534e-01]\n",
      " [2.88876235e-01 7.11123765e-01]\n",
      " [5.49127936e-01 4.50872064e-01]\n",
      " [8.94354582e-01 1.05645411e-01]\n",
      " [2.46800762e-02 9.75319982e-01]\n",
      " [5.08992195e-01 4.91007805e-01]\n",
      " [1.96288869e-01 8.03711116e-01]\n",
      " [8.70763958e-02 9.12923634e-01]\n",
      " [2.11170060e-03 9.97888267e-01]\n",
      " [7.56041184e-02 9.24395919e-01]\n",
      " [1.02596264e-02 9.89740372e-01]\n",
      " [2.61596255e-02 9.73840356e-01]\n",
      " [3.21868923e-03 9.96781230e-01]\n",
      " [7.25897923e-02 9.27410185e-01]\n",
      " [1.62516808e-05 9.99983788e-01]\n",
      " [6.99430048e-01 3.00569952e-01]\n",
      " [1.38807252e-01 8.61192763e-01]\n",
      " [3.43727879e-02 9.65627193e-01]\n",
      " [3.84899005e-02 9.61510062e-01]\n",
      " [1.23605616e-01 8.76394391e-01]\n",
      " [2.73650065e-02 9.72634971e-01]\n",
      " [5.08381948e-02 9.49161828e-01]\n",
      " [1.86247602e-02 9.81375217e-01]\n",
      " [1.52763762e-02 9.84723568e-01]\n",
      " [8.08043929e-04 9.99191940e-01]\n",
      " [6.43530339e-02 9.35646951e-01]\n",
      " [2.05846950e-01 7.94152975e-01]\n",
      " [1.48345195e-02 9.85165477e-01]\n",
      " [3.34564745e-01 6.65435255e-01]\n",
      " [4.13025111e-01 5.86974859e-01]\n",
      " [3.50538522e-01 6.49461448e-01]\n",
      " [5.21772385e-01 4.78227586e-01]\n",
      " [1.52172059e-01 8.47827911e-01]\n",
      " [8.18771496e-02 9.18122828e-01]\n",
      " [2.21942037e-01 7.78057992e-01]\n",
      " [2.83361346e-01 7.16638625e-01]\n",
      " [2.40494255e-02 9.75950658e-01]\n",
      " [1.83271602e-01 8.16728354e-01]\n",
      " [4.77820076e-02 9.52217996e-01]\n",
      " [6.50578737e-02 9.34942067e-01]\n",
      " [2.64054775e-01 7.35945284e-01]\n",
      " [5.12514822e-02 9.48748529e-01]\n",
      " [3.02826971e-01 6.97173059e-01]\n",
      " [1.08625053e-03 9.98913765e-01]\n",
      " [5.80789387e-01 4.19210583e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred_probsFalling = F.softmax(pred_logits_tensorFalling, dim=1).cpu().data.numpy()\n",
    "print (pred_probsFalling)\n",
    "pred_probsNonFalling = F.softmax(pred_logits_tensorNonFalling, dim=1).cpu().data.numpy()\n",
    "print (pred_probsNonFalling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WAD0WkYxR1av"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "accurateFalling=0\n",
    "for i in range(len(pred_probsFalling)):\n",
    "  if (pred_probsFalling[i][0]> 0.5):\n",
    "    accurateFalling= accurateFalling +1 \n",
    "i=0\n",
    "accurateNonFalling=0\n",
    "for i in range(len(pred_probsNonFalling)):\n",
    "  if (pred_probsNonFalling[i][1]> 0.5):\n",
    "    accurateNonFalling= accurateNonFalling +1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Or1NdOxmS37b"
   },
   "outputs": [],
   "source": [
    "overallAccuracy = (accurateNonFalling+accurateFalling)/(len(img_listFalling)+len(img_listNonFalling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1575488581825,
     "user": {
      "displayName": "Muhammad Arslan",
      "photoUrl": "",
      "userId": "03998929032390632573"
     },
     "user_tz": -300
    },
    "id": "8Mi4fcvyVcns",
    "outputId": "35ba9b8a-024d-433f-edf4-58683f50f466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "print (accurateFalling)\n",
    "print (accurateNonFalling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1575488583951,
     "user": {
      "displayName": "Muhammad Arslan",
      "photoUrl": "",
      "userId": "03998929032390632573"
     },
     "user_tz": -300
    },
    "id": "1Ch75_7uWArO",
    "outputId": "4a246363-8844-40d2-8d6f-e921d8e51055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665\n"
     ]
    }
   ],
   "source": [
    "print (overallAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKr4z1T4vde5"
   },
   "outputs": [],
   "source": [
    "ig, axs = plt.subplots(1, len(img_listFalling), figsize=(150, 150))\n",
    "for i, img in enumerate(img_listFalling):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"{:.0f}%Falling , {:.0f}% Non-Falling\".format(100*pred_probsFalling[i,0],\n",
    "                                                          100*pred_probsFalling[i,1]))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTLbRFdQvja9"
   },
   "outputs": [],
   "source": [
    "ig, axs = plt.subplots(1, len(img_listNonFalling), figsize=(150, 150))\n",
    "for i, img in enumerate(img_listNonFalling):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"{:.0f}%Falling , {:.0f}% Non-Falling\".format(100*pred_probsNonFalling[i,0],\n",
    "                                                          100*pred_probsNonFalling[i,1]))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlekgtgoX5S8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1580210253386,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "N64FRzhVX45J",
    "outputId": "ff618d8c-4eba-433f-d4d7-d0aee687b1f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(22, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 99\n",
    "device = 'cuda'\n",
    "model = torch.load('weights/raw-face-hand-pose-d/rfhp_epoch_%d.pth'%(epoch)).to(device)\n",
    "optimizer = optim.Adam(model.fc.parameters(),lr=0.01)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37316,
     "status": "ok",
     "timestamp": 1580210298059,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "pvGmSVFIX4FD",
    "outputId": "112e0158-c055-4430-b40e-fade1995a867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "target = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for inputs , labels in dataloaders['validation']:\n",
    "\n",
    "    #if iteration == 150:\n",
    "    #  break\n",
    "    iteration += 1\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        pred_logits_tensorFalling = model(inputs)\n",
    "        predictions.append(pred_logits_tensorFalling)\n",
    "        target.append(labels)\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1580210411990,
     "user": {
      "displayName": "Ahsan Abbas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCjNOYV6iDDzFHqzUS2lbzEULNVhoSAQuYCgQvp=s64",
      "userId": "03898905081553655167"
     },
     "user_tz": -300
    },
    "id": "y1mvqcWgWx8Z",
    "outputId": "cd128096-f6e7-483a-e9d8-3af64519452e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 60\n",
      "total 100\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "\n",
    "for pred in predictions:\n",
    "\n",
    "    out.append( torch.argmax(pred).item()) \n",
    "\n",
    "acc = 0\n",
    "for i,tar in enumerate(target):\n",
    "    if tar.item() == out[i]:\n",
    "      acc += 1\n",
    "\n",
    "print(\"acc\", acc)\n",
    "print(\"total\",len(out))\n",
    "print(acc/len(out))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "alpha-Resnet(Raw+Face+Hand+Pose)-Pose as Depth.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
